{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "# %pip install mediapipe opencv-python matplotlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing the expected poses in a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting workout timer to 30 seconds\n",
    "timeout = 30\n",
    "# initializing the Landmarks array\n",
    "correct_landmarks = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct pose recorded successfully!\n"
     ]
    }
   ],
   "source": [
    "workout_time = time.time() + timeout + 10   # 30 seconds from now (10 seconds for the user to get ready)\n",
    "cap = cv2.VideoCapture(0)\n",
    "#recording video\n",
    "# frame_width = int(cap.get(3))\n",
    "# frame_height = int(cap.get(4))\n",
    "# size = (frame_width, frame_height)\n",
    "# record = cv2.VideoWriter('expected.avi', cv2.VideoWriter_fourcc(*'MJPG'), 10, size)\n",
    "# setting up mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened() and time.time() < workout_time:\n",
    "        ret, frame = cap.read()\n",
    "        # detect pose landmarks and render them on the image\n",
    "        # convert the image from BGR to RGB (opneCV uses BGR by default)\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        # make detection from pose instance\n",
    "        results = pose.process(image)\n",
    "        correct_landmarks = np.append(correct_landmarks, results.pose_landmarks)\n",
    "        # print(results.pose_landmarks)\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # print(results)\n",
    "        # render pose landmarks on the image\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(51,255,51), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(51,153,255), thickness=2, circle_radius=2))\n",
    "        \n",
    "        # cv2.imshow('MediaPipe Pose', frame)\n",
    "        cv2.imshow('MediaPipe Pose', image)\n",
    "        # recording video\n",
    "        # record.write(image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    # record.release()\n",
    "    cv2.destroyAllWindows() \n",
    "    print(\"Correct pose recorded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_landmarks\n",
    "np.save('correct_landmarks.npy', correct_landmarks)\n",
    "# loading the correct landmarks\n",
    "saved_landmarks = np.load('correct_landmarks.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workout_time = time.time() + timeout \n",
    "# correct_landmarks = pd.read_csv('correct_landmarks.csv').to_numpy()  \n",
    "count = 0\n",
    "poses_matched = 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        # make detection from pose instance\n",
    "        current_results = pose.process(image)\n",
    "        # print(results.pose_landmarks)\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        # getting the correct pose landmarks\n",
    "        correct_pose_landmark = saved_landmarks[count % saved_landmarks.shape[0]]\n",
    "        count += 1\n",
    "        #compare the results\n",
    "        match_count = 0\n",
    "        for (act, expected) in zip(current_results.pose_landmarks.landmark, correct_pose_landmark.landmark):\n",
    "            # calculate the distance between the actual and expected landmarks\n",
    "            dist = np.sqrt((act.x - expected.x)**2 + (act.y - expected.y)**2 + (act.z - expected.z)**2)\n",
    "            if dist < 0.25:\n",
    "                match_count += 1\n",
    "        # calculate the percentage of matched landmarks\n",
    "        match_percent = (match_count / len(correct_pose_landmark.landmark)) * 100\n",
    "        text = f\"{round(match_percent, 2)}% match - \"  \n",
    "        # render pose landmarks on the image\n",
    "        if match_percent > 75:\n",
    "            text += \"Correct Pose\"\n",
    "            color = (0, 255, 0)\n",
    "            poses_matched += 1\n",
    "        else:\n",
    "            text+= \"Incorrect Pose\"\n",
    "            color = (0, 0, 255)\n",
    "            mp_drawing.draw_landmarks(image, correct_pose_landmark, mp_pose.POSE_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(51,255,51), thickness=2, circle_radius=2),\n",
    "                    mp_drawing.DrawingSpec(color=(51,153,255), thickness=2, circle_radius=2))    \n",
    "            \n",
    "        mp_drawing.draw_landmarks(image, current_results.pose_landmarks, mp_pose.POSE_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=color, thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=color, thickness=2, circle_radius=2))\n",
    "        cv2.putText(image,text, (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        cv2.imshow('MediaPipe Pose', image)\n",
    "        # render the results from previous cell\n",
    "        sentence = \"No pose detected\"\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q') :\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total poses matched: 88\n",
      "Total poses attempted: 264\n",
      "Accuracy: 33.33%\n"
     ]
    }
   ],
   "source": [
    "# print the results\n",
    "print(f\"Total poses matched: {poses_matched}\")\n",
    "print(f\"Total poses attempted: {count}\")\n",
    "print(f\"Accuracy: {round(poses_matched/count * 100, 2)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06d27cae120c8794265ed279269c4c44da5cbce9399fe3541c085bdf7bc3ff29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
