{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "# %pip install mediapipe opencv-python matplotlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing the expected poses in a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting workout timer to 30 seconds\n",
    "timeout = 20\n",
    "# initializing the Landmarks array\n",
    "correct_landmarks = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct pose recorded successfully!\n"
     ]
    }
   ],
   "source": [
    "workout_time = time.time() + timeout + 10   # 30 seconds from now (10 seconds for the user to get ready)\n",
    "cap = cv2.VideoCapture(0)\n",
    "#recording video\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "size = (frame_width, frame_height)\n",
    "record = cv2.VideoWriter('expected.avi', cv2.VideoWriter_fourcc(*'MJPG'), 10, size)\n",
    "# setting up mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened() and time.time() < workout_time:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Video Ended\")\n",
    "            break\n",
    "        # detect pose landmarks and render them on the image\n",
    "        # convert the image from BGR to RGB (opneCV uses BGR by default)\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        # make detection from pose instance\n",
    "        results = pose.process(image)\n",
    "        correct_landmarks = np.append(correct_landmarks, results.pose_landmarks)\n",
    "        # print(results.pose_landmarks)\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # print(results)\n",
    "        # render pose landmarks on the image\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(51,255,51), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(51,153,255), thickness=2, circle_radius=2))\n",
    "        \n",
    "        # cv2.imshow('MediaPipe Pose', frame)\n",
    "        cv2.imshow('MediaPipe Pose', image)\n",
    "        # recording video\n",
    "        record.write(image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    record.release()\n",
    "    cv2.destroyAllWindows() \n",
    "    print(\"Correct pose recorded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of correct_landmarks: (229,)\n",
      "Pose 0\n",
      "x: 0.5051068067550659\n",
      "y: 0.2619391679763794\n",
      "z: -1.6423507928848267\n",
      "visibility: 0.9995908141136169\n",
      "\n",
      "x: 0.5406193733215332\n",
      "y: 0.19901643693447113\n",
      "z: -1.6303415298461914\n",
      "visibility: 0.9981491565704346\n",
      "\n",
      "x: 0.5601483583450317\n",
      "y: 0.2009599208831787\n",
      "z: -1.6302598714828491\n",
      "visibility: 0.9986960291862488\n",
      "\n",
      "x: 0.5782780647277832\n",
      "y: 0.2027454972267151\n",
      "z: -1.6302030086517334\n",
      "visibility: 0.9971244931221008\n",
      "\n",
      "x: 0.4810393750667572\n",
      "y: 0.1843211054801941\n",
      "z: -1.6263576745986938\n",
      "visibility: 0.9986345171928406\n",
      "\n",
      "Pose 1\n",
      "x: 0.5048967599868774\n",
      "y: 0.2617865800857544\n",
      "z: -1.615944504737854\n",
      "visibility: 0.9995816349983215\n",
      "\n",
      "x: 0.5406160950660706\n",
      "y: 0.1979180872440338\n",
      "z: -1.596559762954712\n",
      "visibility: 0.9981552958488464\n",
      "\n",
      "x: 0.5599924325942993\n",
      "y: 0.1996561884880066\n",
      "z: -1.5965086221694946\n",
      "visibility: 0.9986988306045532\n",
      "\n",
      "x: 0.5776458382606506\n",
      "y: 0.20129436254501343\n",
      "z: -1.5963817834854126\n",
      "visibility: 0.9971731305122375\n",
      "\n",
      "x: 0.4797060489654541\n",
      "y: 0.18422898650169373\n",
      "z: -1.5975397825241089\n",
      "visibility: 0.9986228346824646\n",
      "\n",
      "Pose 2\n",
      "x: 0.5046451091766357\n",
      "y: 0.26190438866615295\n",
      "z: -1.615436315536499\n",
      "visibility: 0.9995720982551575\n",
      "\n",
      "x: 0.5405936241149902\n",
      "y: 0.19790595769882202\n",
      "z: -1.5953960418701172\n",
      "visibility: 0.9981642365455627\n",
      "\n",
      "x: 0.5597711205482483\n",
      "y: 0.19964784383773804\n",
      "z: -1.5953547954559326\n",
      "visibility: 0.998699963092804\n",
      "\n",
      "x: 0.5769650340080261\n",
      "y: 0.20128710567951202\n",
      "z: -1.5952194929122925\n",
      "visibility: 0.9972221851348877\n",
      "\n",
      "x: 0.47863489389419556\n",
      "y: 0.18430255353450775\n",
      "z: -1.5966092348098755\n",
      "visibility: 0.9986158609390259\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# correct_landmarks\n",
    "np.save('correct_landmarks.npy', correct_landmarks)\n",
    "# loading the correct landmarks\n",
    "saved_landmarks = np.load('correct_landmarks.npy', allow_pickle=True)\n",
    "print(f\"shape of correct_landmarks: {correct_landmarks.shape}\")\n",
    "#printing few landmarks:\n",
    "for i in range(3):\n",
    "    print(f\"Pose {i}\")\n",
    "    for j in range(5):\n",
    "        if correct_landmarks[i] is not None:\n",
    "            print(correct_landmarks[i].landmark[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workout_time = time.time() + timeout \n",
    "# correct_landmarks = pd.read_csv('correct_landmarks.csv').to_numpy()  \n",
    "count = 0\n",
    "poses_matched = 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "#recording video\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "size = (frame_width, frame_height)\n",
    "record = cv2.VideoWriter('actual.avi', cv2.VideoWriter_fourcc(*'MJPG'), 10, size)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Workout Ended!\")\n",
    "            break\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        # make detection from pose instance\n",
    "        current_results = pose.process(image)\n",
    "        # print(results.pose_landmarks)\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        # getting the correct pose landmarks\n",
    "        correct_pose_landmark = correct_landmarks[count % saved_landmarks.shape[0]]\n",
    "        count += 1\n",
    "        #compare the results\n",
    "        match_count = 0\n",
    "        color = (0, 0, 255)\n",
    "        text = \"No Pose\"\n",
    "        if(correct_pose_landmark is not None):\n",
    "            for (act, expected) in zip(current_results.pose_landmarks.landmark, correct_pose_landmark.landmark):\n",
    "                # calculate the distance between the actual and expected landmarks\n",
    "                dist = np.sqrt((act.x - expected.x)**2 + (act.y - expected.y)**2 + (act.z - expected.z)**2)\n",
    "                if dist < 0.25:\n",
    "                    match_count += 1\n",
    "            # calculate the percentage of matched landmarks\n",
    "            match_percent = (match_count / len(correct_pose_landmark.landmark)) * 100\n",
    "            text = f\"{round(match_percent, 2)}% match - \"  \n",
    "            # render pose landmarks on the image\n",
    "            if match_percent > 75:\n",
    "                text += \"Correct Pose\"\n",
    "                color = (0, 255, 0)\n",
    "                poses_matched += 1\n",
    "            else:\n",
    "                text+= \"Incorrect Pose\"\n",
    "                color = (0, 0, 255)\n",
    "                mp_drawing.draw_landmarks(image, correct_pose_landmark, mp_pose.POSE_CONNECTIONS,\n",
    "                        mp_drawing.DrawingSpec(color=(51,255,51), thickness=2, circle_radius=2),\n",
    "                        mp_drawing.DrawingSpec(color=(51,153,255), thickness=2, circle_radius=2))    \n",
    "        else:\n",
    "            print(\"No Pose Detected!\")\n",
    "            \n",
    "        mp_drawing.draw_landmarks(image, current_results.pose_landmarks, mp_pose.POSE_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=color, thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=color, thickness=2, circle_radius=2))\n",
    "        cv2.putText(image,text, (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        cv2.imshow('MediaPipe Pose', image)\n",
    "        record.write(image)\n",
    "        \n",
    "        # render the results from previous cell\n",
    "        sentence = \"No pose detected\"\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q') :\n",
    "            break\n",
    "    cap.release()\n",
    "    record.release()\n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Output Results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total poses matched: 202\n",
      "Total poses attempted: 320\n",
      "Accuracy: 63.12%\n"
     ]
    }
   ],
   "source": [
    "# print the results\n",
    "print(f\"Total poses matched: {poses_matched}\")\n",
    "print(f\"Total poses attempted: {count}\")\n",
    "print(f\"Accuracy: {round(poses_matched/count * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "06d27cae120c8794265ed279269c4c44da5cbce9399fe3541c085bdf7bc3ff29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
